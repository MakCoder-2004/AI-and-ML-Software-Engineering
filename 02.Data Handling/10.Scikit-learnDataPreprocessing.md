# Scikit-learn Data Preprocessing

## Difference Between `fit`, `transform`, and `fit_transform`

| Method            | Purpose                                                                                              | Syntax Example                                  | Example with Data             |
| ----------------- | ---------------------------------------------------------------------------------------------------- | ----------------------------------------------- | ----------------------------- |
| `fit()`           | Learn parameters from data                                                                           | `estimator.fit(X)`                              | `scaler.fit(train_data)`      |
| `transform()`     | Apply learned parameters to new data                                                                 | `transformed_data = estimator.transform(X)`     | `scaler.transform(test_data)` |
| `fit_transform()` | Learn & apply in one step                                                                            | `transformed_data = estimator.fit_transform(X)` | `scaler.fit_transform(data)`  |
| **Usage Tip**     | `fit` = training data only, `transform` = apply on any data, `fit_transform` = one-step on same data |                                                 |                               |

---

## Feature Scaling & Normalization

### Min-Max Scaling

Scales features to a fixed range (default 0 to 1).

```python
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df[['col1','col2']] = scaler.fit_transform(df[['col1','col2']])
```

ðŸ“Œ *Use when:* You want all features on the same scale.

---

### Standardization (Z-score Scaling)

Transforms data to mean=0, variance=1.

```python
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df[['col1','col2']] = scaler.fit_transform(df[['col1','col2']])
```

ðŸ“Œ *Use when:* Features have different units & need standard normal distribution.

---

### Robust Scaling

Removes the effect of outliers using median & IQR.

```python
from sklearn.preprocessing import RobustScaler
scaler = RobustScaler()
df[['col1','col2']] = scaler.fit_transform(df[['col1','col2']])
```

ðŸ“Œ *Use when:* Data contains **outliers**.

---

### Normalization (Row-wise L1/L2 norm)

```python
from sklearn.preprocessing import normalize
df[['col1','col2']] = normalize(df[['col1','col2']], norm='l2')
```

ðŸ“Œ *Use when:* Each sample (row) needs unit norm.

---

## Feature Transformation

### Polynomial Features

Generates polynomial & interaction features.

```python
from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree=2, include_bias=False)
poly_features = poly.fit_transform(df[['col1','col2']])
```

ðŸ“Œ *Use when:* Adding non-linear relationships for models.

---

### Power Transformation (Yeo-Johnson, Box-Cox)

Stabilizes variance, makes data more Gaussian.

```python
from sklearn.preprocessing import PowerTransformer
pt = PowerTransformer(method='yeo-johnson')
df[['col1','col2']] = pt.fit_transform(df[['col1','col2']])
```

ðŸ“Œ *Use when:* Data is highly skewed.

---

### Quantile Transformation

Maps data to uniform or normal distribution.

```python
from sklearn.preprocessing import QuantileTransformer
qt = QuantileTransformer(output_distribution='normal')
df[['col1','col2']] = qt.fit_transform(df[['col1','col2']])
```

ðŸ“Œ *Use when:* Need **robust normalization** against outliers.

---

## Encoding Categorical Features

### Label Encoding

```python
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['Category'] = le.fit_transform(df['Category'])
```

ðŸ“Œ *Use when:* Converting categories â†’ numeric labels.

---

### One-Hot Encoding

```python
from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder(sparse=False)
ohe_data = ohe.fit_transform(df[['Category']])
```

ðŸ“Œ *Use when:* Creating binary columns for each category.

---

### Ordinal Encoding

```python
from sklearn.preprocessing import OrdinalEncoder
oe = OrdinalEncoder(categories=[['Low','Medium','High']])
df[['Category']] = oe.fit_transform(df[['Category']])
```

ðŸ“Œ *Use when:* Categories have **order**.

---

## Data Cleaning & Imputation

### Simple Imputer

Replaces missing values with mean, median, or constant.

```python
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')
df[['col1']] = imputer.fit_transform(df[['col1']])
```

ðŸ“Œ *Use when:* Handling NaN values quickly.

---

### KNN Imputer

Uses K-nearest neighbors to impute missing values.

```python
from sklearn.impute import KNNImputer
imputer = KNNImputer(n_neighbors=3)
df[['col1','col2']] = imputer.fit_transform(df[['col1','col2']])
```

ðŸ“Œ *Use when:* Data missingness is related to similar samples.

---

### Iterative Imputer

Predicts missing values using other features.

```python
from sklearn.experimental import enable_iterative_imputer  
from sklearn.impute import IterativeImputer
imputer = IterativeImputer()
df[['col1','col2']] = imputer.fit_transform(df[['col1','col2']])
```

ðŸ“Œ *Use when:* Want **regression-based imputation**.

---

## Binarization

```python
from sklearn.preprocessing import Binarizer
binarizer = Binarizer(threshold=0.5)
df[['col1']] = binarizer.fit_transform(df[['col1']])
```

ðŸ“Œ *Use when:* Converting numeric â†’ binary (0/1).

---

## Summary Table

| Transformation          | Function            | Use Case                           |
| ----------------------- | ------------------- | ---------------------------------- |
| Scaling                 | MinMaxScaler        | Scale data to \[0,1]               |
| Standardization         | StandardScaler      | Mean=0, Var=1                      |
| Robust Scaling          | RobustScaler        | Outlier-resistant scaling          |
| Normalization           | normalize           | Unit norm rows                     |
| Polynomial Features     | PolynomialFeatures  | Add polynomial features            |
| Power Transformation    | PowerTransformer    | Reduce skewness                    |
| Quantile Transformation | QuantileTransformer | Uniform/Normal scaling             |
| Label Encoding          | LabelEncoder        | Categorical â†’ numeric              |
| One-Hot Encoding        | OneHotEncoder       | Categorical â†’ binary columns       |
| Ordinal Encoding        | OrdinalEncoder      | Ordered categories                 |
| Simple Imputation       | SimpleImputer       | Mean/Median fill                   |
| KNN Imputation          | KNNImputer          | KNN-based missing value imputation |
| Iterative Imputation    | IterativeImputer    | Predictive imputation              |
| Binarization            | Binarizer           | Numeric â†’ Binary                   |

---