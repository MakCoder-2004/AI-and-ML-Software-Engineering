# NumPy: A Comprehensive Guide

NumPy (Numerical Python) is a fundamental package for scientific computing in Python. It provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.

## Table of Contents

1. Introduction to NumPy
2. NumPy Environment Setup
3. Array Creation
4. Vector Operations
5. Matrix Operations
6. Linear Algebra with NumPy
7. Eigenvalues and Eigenvectors

---

## Introduction to NumPy

NumPy is an open-source library for working efficiently with arrays. Developed in 2005 by Travis Oliphant, the name stands for Numerical Python. It is a critical data science library in Python, and many other libraries depend on it.

**Why is NumPy so popular?**

* **Efficiency:** Improves ease and performance of working with multidimensional arrays.
* **Functionality:** Provides mathematical and logical operations, Fourier transforms, shape manipulation, and linear algebra routines.
* **MatLab Replacement:** Along with SciPy and Matplotlib, serves as a powerful alternative to MatLab.

---

## NumPy Environment Setup

Install NumPy using pip:

```bash
pip install numpy
```

Import NumPy in Python:

```python
import numpy
# or
import numpy as np  # Common convention
```

---

## Array Creation

NumPy arrays are n-dimensional data structures:

* **1D Array:** Vector
* **2D Array:** Matrix
* **3D Array:** Tensor

**Creating Arrays**

\*\*1D Array (Vector): \*\*

```python
import numpy as np

# Horizontal vector
vector1 = np.array([1, 2, 3])
print("Horizontal Vector:")
print(vector1)

# Vertical vector
vector2 = np.array([[10], [20], [30]])
print("Vertical Vector:")
print(vector2)
```

**2D Array (Matrix):**

```python
# Using lists
matrix = np.array([[1, 2, 3], [4, 5, 6]])
print("Matrix:")
print(matrix)

# Using np.arange and reshape
vector = np.arange(1, 13)  # Creates 1D array from 1 to 12
matrix = vector.reshape(3, 4)  # Reshapes into 3x4 matrix
print("Reshaped Matrix:")
print(matrix)
```

**3D Array (Tensor):**

```python
tensor = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]])
print("3D Tensor:")
print(tensor)
```

---

## Vector Operations

**Basic Operations:**

```python
vector1 = np.array([5, 6, 9])
vector2 = np.array([1, 2, 3])

# Addition
print("Addition:", vector1 + vector2)
# Subtraction
print("Subtraction:", vector1 - vector2)
# Multiplication
print("Multiplication:", vector1 * vector2)
# Division
print("Division:", vector1 / vector2)
```

**Vector Norms**

* **Norm (Manhattan Distance):**

```python
from numpy.linalg import norm
arr = np.array([1, 2, 3, 4, 5])
norm = norm(arr, 1)
print("L1 Norm:", l1_norm)
```

* **Norm (Euclidean Distance):**

```python
from numpy.linalg import norm
arr = np.array([1, 2, 3, 4, 5])
norm = norm(arr)
print("L2 Norm:", l2_norm)
```

---

## Matrix Operations

**Matrix Determinant:**

```python
matrix = np.array([[50, 29], [30, 44]])
det = np.linalg.det(matrix)
print("Determinant:", int(det))
```

**Matrix Rank:**

```python
matrix = np.array([[1, 2, 1], [3, 4, 7], [3, 6, 3]])
rank = np.linalg.matrix_rank(matrix)
print("Rank:", rank)
```

**Matrix Inverse:**

```python
matrix = np.array([[3, 7], [2, 5]])
inv_matrix = np.linalg.inv(matrix)
print("Inverse Matrix:", inv_matrix)
```

---

## Linear Algebra with NumPy

**Solving Linear Equations:**

```python
A = np.array([[3, 1], [1, 2]])
B = np.array([9, 8])
x = np.linalg.solve(A, B)
print("Solution:", x)
```

---

## Eigenvalues and Eigenvectors

**Finding Eigenvalues and Eigenvectors:**

```python
matrix = np.array([[0, 2], [2, 3]])
eigenvalues, eigenvectors = np.linalg.eig(matrix)
print("Eigenvalues:", eigenvalues)
print("Eigenvectors:")
print(eigenvectors)
```

**Example:**

```python
A = np.array([[-6, 3], [4, 5]])
eigenvalues, eigenvectors = np.linalg.eig(A)
print("Eigenvalues:", eigenvalues)
print("Eigenvectors:")
print(eigenvectors)
```

---

# Linear Algebra Rules in NumPy

## Matrix Inversion

**Rule:**

For a square matrix A, its inverse A^-1 satisfies:

$$
A \times A^{-1} = I
$$

where I is the identity matrix.

For a 2x2 matrix:

$$
\begin{bmatrix}
a & b \\
c & d
\end{bmatrix}^{-1} = \frac{1}{ad - bc} \times \begin{bmatrix} d & -b \\ -c & a \end{bmatrix}
$$

**Python Implementation:**

```python
import numpy as np

# Create a 2x2 matrix
A = np.array([[4, 7], [2, 6]])

# Calculate inverse
A_inv = np.linalg.inv(A)

print("Original matrix:")
print(A)
print("\nInverse matrix:")
print(A_inv)
print("\nProduct of A and A_inv (should be identity matrix):")
print(np.round(A @ A_inv))  # Using @ for matrix multiplication
```

---

## Eigenvalues and Eigenvectors

**Rule:**

For a square matrix A, an eigenvector v and eigenvalue $\lambda$ satisfy:

$$
A v = \lambda v
$$

Eigenvalues are found by solving:

$$
|A - \lambda I| = 0
$$

Example for matrix:

$$
\begin{bmatrix}
-6 & 3 \\
4 & 5
\end{bmatrix}
$$

**Python Implementation:**

```python
import numpy as np

# Create a matrix
A = np.array([[-6, 3], [4, 5]])

# Calculate eigenvalues and eigenvectors
eigenvalues, eigenvectors = np.linalg.eig(A)

print("Eigenvalues:")
print(eigenvalues)
print("\nEigenvectors (as columns):")
print(eigenvectors)

# Verify A v = λ v for the first eigenvalue/eigenvector
λ = eigenvalues[0]
v = eigenvectors[:, 0]
print("\nVerification Av = λv:")
print("A @ v:", A @ v)
print("λ * v:", λ * v)
```

---

## Matrix Multiplication

**Rule:**

For matrices A (m×n) and B (n×p), their product C = AB is (m×p) where:

$$
C_{ij} = \sum_{k=1}^{n} A_{ik}B_{kj}
$$

**Python Implementation:**

```python
import numpy as np

A = np.array([[1, 2], [3, 4]])
B = np.array([[5, 6], [7, 8]])

# Matrix multiplication
C = np.matmul(A, B)  # or A @ B

print("Matrix A:")
print(A)
print("\nMatrix B:")
print(B)
print("\nProduct A @ B:")
print(C)
```

---

## Determinant

**Rule:**

For a square matrix, the determinant is a scalar value that can determine if the matrix is invertible (non-zero determinant).

For a 2x2 matrix:

$$
\det \begin{bmatrix} a & b \\ c & d \end{bmatrix} = ad - bc
$$

**Python Implementation:**

```python
import numpy as np

A = np.array([[4, 7], [2, 6]])

det_A = np.linalg.det(A)

print("Matrix:")
print(A)
print("\nDeterminant:", det_A)
print("Is matrix invertible?", not np.isclose(det_A, 0))
```

---

## Matrix Transpose

**Rule**
The transpose of a matrix A, denoted Aᵗ, is formed by flipping rows and columns:

$(A^T)_{ij} = A_{ji}$

**Python Implementation**

```python
import numpy as np

A = np.array([[1, 2, 3], [4, 5, 6]])

A_transpose = A.T

print("Original matrix:")
print(A)
print("\nTransposed matrix:")
print(A_transpose)
```

---

## Trace of a Matrix

**Rule**
The trace of a square matrix is the sum of its diagonal elements:

$\text{tr}(A) = \sum_{i=1}^n A_{ii}$

**Python Implementation**

```python
import numpy as np

A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])

trace_A = np.trace(A)

print("Matrix:")
print(A)
print("\nTrace of matrix:", trace_A)
```

---

## Singular Value Decomposition (SVD)

**Rule**
Any matrix A can be decomposed as:

$A = U \, \Sigma \, V^T$

where U and V are orthogonal matrices, and Σ is a diagonal matrix of singular values.

**Python Implementation**

```python
import numpy as np

A = np.array([[1, 2], [3, 4], [5, 6]])

U, S, VT = np.linalg.svd(A)

print("Matrix A:")
print(A)
print("\nU:")
print(U)
print("\nSingular values:")
print(S)
print("\nV transpose matrix:")
print(VT)

# Reconstruct original matrix
Sigma = np.zeros((A.shape[0], A.shape[1]))
Sigma[:len(S), :len(S)] = np.diag(S)
reconstructed_A = np.dot(U, np.dot(Sigma, VT))

print("\nReconstructed matrix (should match original):")
print(reconstructed_A)
```

---

## Solving Linear Systems

**Rule**
For a system of linear equations Ax = b, the solution is:

$x = A^{-1} b$

(when A is invertible)

**Python Implementation**

```python
import numpy as np

# Coefficient matrix
A = np.array([[3, 1], [1, 2]])
# Right-hand side vector
b = np.array([9, 8])

# Solve the system
x = np.linalg.solve(A, b)

print("Solution x:")
print(x)

# Verify solution
print("\nCheck: Ax should equal b?", np.allclose(np.dot(A, x), b))
```
---