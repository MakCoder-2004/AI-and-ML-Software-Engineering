# Pandas in Python

This guide covers Pandas in detail, with visualized concepts, explanations, and practical usage scenarios for each function. It also introduces Scikit-learn functions, explaining when and why to use them.

---

## Introduction to Pandas

**Pandas** is a Python library for data analysis and manipulation.

* Created by Wes McKinney in 2008.
* Stands for "Panel Data" and "Python Data Analysis".
* Works well with NumPy, Matplotlib, and Scikit-learn.

**Installation:**
```bash
pip install pandas
```

**Import:**
```python
import pandas as pd
```

---

## Data Cleaning

**Missing Data:**
```python
df.dropna()              # remove rows with NaN
df.fillna(0)             # replace NaN with 0
df.fillna(df.mean())     # replace NaN with mean
```
ðŸ“Œ *Use when:* Handling incomplete datasets.

---

## Grouping & Aggregation

```python
df.groupby('Category').mean()
df.groupby('Category').agg({'Sales':'sum','Profit':'mean'})
```

ðŸ“Œ *Use when:* Summarizing data by categories.

---

## Combining DataFrames

```python
pd.merge(df1, df2, on='ID', how='inner')    # merge on common column
pd.concat([df1, df2], axis=0)               # stack vertically
```

ðŸ“Œ *Use when:* Merging datasets or appending rows.

---

## Pivot Tables

```python
df.pivot_table(values='Sales', index='Category', columns='Region', aggfunc='sum')
```

ðŸ“Œ *Use when:* Summarizing data with multiple dimensions.

---

## Visualization

```python
import matplotlib.pyplot as plt
df['Column'].hist()
df.plot(kind='line', x='Date', y='Sales')
plt.show()
```

ðŸ“Œ *Use when:* Quickly plotting data directly from Pandas.

---

## Scikit-learn Preprocessing

### Difference Between `fit`, `transform`, and `fit_transform`

| Method                                                                                                      | Purpose                                  | Syntax Example                                  | Example with Data                                   |
| ----------------------------------------------------------------------------------------------------------- | ---------------------------------------- | ----------------------------------------------- | --------------------------------------------------- |
| `fit()`                                                                                                     | Learn parameters of transformation       | `estimator.fit(X)`                              | `estimator.fit(train_data)`                         |
| `transform()`                                                                                               | Apply learned transformation to new data | `transformed_data = estimator.transform(X)`     | `transformed_data = estimator.transform(test_data)` |
| `fit_transform()`                                                                                           | Learn and apply transformation to data   | `transformed_data = estimator.fit_transform(X)` | `transformed_data = estimator.fit_transform(data)`  |
| ðŸ“Œ *Use when:* `fit` is for training, `transform` for applying, and `fit_transform` for doing both at once. |                                          |                                                 |                                                     |

**Example â€“ Rescaling:**

```python
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df[['col1', 'col2']] = scaler.fit_transform(df[['col1', 'col2']])
```

ðŸ“Œ *Use when:* Scaling values between 0 and 1.

**Normalization:**

```python
from sklearn.preprocessing import normalize
df[['col1', 'col2']] = normalize(df[['col1', 'col2']], norm='l2')
```

ðŸ“Œ *Use when:* You want each row to have unit norm.

**Binarization:**

```python
from sklearn.preprocessing import Binarizer
binarizer = Binarizer(threshold=0.5)
df[['col1']] = binarizer.fit_transform(df[['col1']])
```

ðŸ“Œ *Use when:* Converting numerical features to binary based on a threshold.

**Standardization:**

```python
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df[['col1', 'col2']] = scaler.fit_transform(df[['col1', 'col2']])
```

ðŸ“Œ *Use when:* Making data mean=0 and variance=1.

**Label Encoding:**

```python
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['Category'] = le.fit_transform(df['Category'])
```

ðŸ“Œ *Use when:* Converting categories to numeric labels.

**One-Hot Encoding:**

```python
from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder(sparse=False)
ohe_data = ohe.fit_transform(df[['Category']])
```

ðŸ“Œ *Use when:* Creating binary columns for each category.

---

## Data Imputation

```python
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
df[['col1']] = imputer.fit_transform(df[['col1']])
```

ðŸ“Œ *Use when:* Replacing missing values with mean.

---

## EDA (Exploratory Data Analysis)

```python
import seaborn as sns
sns.heatmap(df.corr(), annot=True)
```

ðŸ“Œ *Use when:* Visualizing correlations between numeric variables.

---

## Additional Useful Functions

Each of these is used when preparing or cleaning your dataset:

```python
data.isnull().sum()          # Missing value counts
data.fillna(0, inplace=True) # Fill NaNs with 0
data.dropna(inplace=True)    # Drop NaNs
data.sort_values(by='col')   # Sort by column
data.groupby('Category').mean() # Group and summarize
data.rename(columns={'old': 'new'}, inplace=True) # Rename columns
data.reset_index(drop=True, inplace=True) # Reset index
data.set_index('col', inplace=True) # Set new index
data['col'].value_counts()  # Frequency of values
data['col'] = data['col'].apply(lambda x: x * 2) # Apply function
data['col'].unique()        # Unique values
data['col'].nunique()       # Count of unique values
```

---

## Summary Table

| Function            | Description & When to Use |
| ------------------- | ------------------------- |
| `read_csv()`        | Load CSV files            |
| `read_excel()`      | Load Excel files          |
| `head()`            | View first rows           |
| `tail()`            | View last rows            |
| `info()`            | Check structure           |
| `describe()`        | Get statistics            |
| `dropna()`          | Remove NaNs               |
| `fillna()`          | Replace NaNs              |
| `drop_duplicates()` | Remove duplicates         |
| `duplicated()`      | Find duplicates           |
| `loc[]`             | Select by labels          |
| `iloc[]`            | Select by position        |
| `groupby()`         | Group data                |
| `merge()`           | Merge DataFrames          |
| `concat()`          | Append DataFrames         |
| `pivot_table()`     | Summarize multi-dimension |
| `apply()`           | Apply custom functions    |
| `sort_values()`     | Sort data                 |

---
